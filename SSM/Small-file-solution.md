小文件存储的挑战和SSM的解决方案
==============

痛点：
-------------------

HDFS从设计初衷就是为了存储一次写入多次读取的大数据，对于小文件支持先天不足，原因有二：  

1，因为存储于HDFS中的数据需要在namenode中存放元数据信息，大量的小文件意味着大量的元数据，会占用namespace大量空间。  
2，小文件的读写速度慢，因为对于小文件，查找数据位置在整个数据读写过程中的比重高。  

有很多的尝试去解决小文件问题，其中包括Hadoop HAR，和Sequence File。

但这些尝试也存在问题：  

1，上述两个问题解决不彻底
2，对客户不同透明
3，对Hadoop框架进行了重大修改

设计目标：
-------------------

1，更好地读取性能  
2，至少不差的写入性能  
3，优化namespace和compact namespace  
4，透明化小文件读写  

应用场景：
----------------

1，写小文件  

在SSM框架中，新的SmartDFSClient会替代HDFSClient，来提供数据服务。所有文件的写入由用户设计具体规则。  
对于小文件，可以指定其存入专门存储小文件的容器中，修改容器信息，而不是在namenode新建元数据，namespace会被节约。

2，读小文件

与写相对的，读取时，SmartDFSClient会询问SSMServer目标文件存储的容器和其在容器中的偏移量，长度，然后读取。

3，压缩小文件  

对于已经存入在HDFS中的小文件，SSM支持规则设置，压缩这些小文件之后删除原文件。

性能考量：
---------------

小文件读写的瓶颈主要存在于磁盘IO，SSM会权衡节点状况，选择缓存一整个容器block，使后续读写加快。
另外SSM的动态存储策略会将频繁操作的“热”数据存储于SSD，以加快性能。
另外一个考虑是小文件的批量操作，在一些场合，特别是深度学习训练项目中，存储于同一个容器的小文件可能同时被读取，  
因此SSM将提供批量操作的API。

安全考虑：
-------------------

SSMServer会检查用户是否有权限访问管理的小文件，小文件只可以被SSM访问操作，终端用户和SmartDFSCLient不能操作文件。


